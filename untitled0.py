# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CxmVWGcZlLQQemysMXWexDjnNBYob7k4
"""

!pip install kaggle

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d pkdarabi/brain-tumor-image-dataset-semantic-segmentation

!unzip brain-tumor-image-dataset-semantic-segmentation.zip

# Estructura del DF
import json

def print_structure (d, indent=0):
    if isinstance(d,dict):
        for key , value in d.items():
            print(' ' * indent + str(key))
            print_structure(value,indent+1)
    elif isinstance(d, list):
        print(' ' * indent + "list of length {} containing : ".format(len(d)))
        if d:
            print_structure(d[0],indent+1)

with open('/content/valid/_annotations.coco.json','r') as file:
    data = json.load(file)

print_structure(data)

from pycocotools.coco import COCO

train_dir = '/content/train'
val_dir = '/content/valid'
test_dir = '/content/test'

train_annotation_file = '/content/train/_annotations.coco.json'
test_annotation_file = '/content/test/_annotations.coco.json'
val_annotation_file = '/content/valid/_annotations.coco.json'

train_coco = COCO(train_annotation_file)
val_coco = COCO(val_annotation_file)
test_coco = COCO(test_annotation_file)

"""# Pipeline de preprocesamiento"""

import os
from PIL import Image
import numpy as np
from pycocotools.coco import COCO

def load_image_and_mask(coco, image_dir, image_id):
    image_info = coco.loadImgs(image_id)[0]
    image_path = os.path.join(image_dir, image_info['file_name'])
    image = Image.open(image_path)
    image = np.array(image)

    ann_ids = coco.getAnnIds(imgIds=image_id)
    anns = coco.loadAnns(ann_ids)
    mask = np.zeros((image_info['height'], image_info['width']))
    for ann in anns:
        mask = np.maximum(mask, coco.annToMask(ann))

    return image, mask

import tensorflow as tf
from PIL import Image
import numpy as np

def create_tf_dataset(coco, image_dir, image_ids):
    def generator():
        for image_id in image_ids:
            yield load_image_and_mask(coco, image_dir, image_id)

    return tf.data.Dataset.from_generator(generator,
                                          output_signature=(tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),
                                                            tf.TensorSpec(shape=(None, None), dtype=tf.uint8)))

train_dataset = create_tf_dataset(train_coco, train_dir, train_coco.getImgIds())
val_dataset = create_tf_dataset(val_coco, val_dir, val_coco.getImgIds())
test_dataset = create_tf_dataset(test_coco, test_dir, test_coco.getImgIds())

import tensorflow as tf

def preprocess(image, mask):

    image = tf.image.resize(image, (512, 512))

    mask = tf.expand_dims(mask, axis=-1)
    mask = tf.image.resize(mask, (512, 512))

    image = tf.cast(image, tf.float32) / 255.0

    return image, mask

train_dataset = create_tf_dataset(train_coco, train_dir, train_coco.getImgIds())
val_dataset = create_tf_dataset(val_coco, val_dir, val_coco.getImgIds())
test_dataset = create_tf_dataset(test_coco, test_dir, test_coco.getImgIds())

img_ids = train_coco.getImgIds()

for i, img_id in enumerate(img_ids[:1]):

    img_info = train_coco.loadImgs(img_id)[0]

    filename = img_info['file_name']
    height = img_info['height']
    width = img_info['width']

    print(f"Archivo: {filename}, Dimensiones: {height}x{width}")

"""# Metricas"""

import tensorflow as tf
import tensorflow.keras.backend as K

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

def combined_loss(y_true, y_pred):
    dice = dice_loss(y_true, y_pred)
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    return 0.6 * dice + 0.4 * bce

"""# Aumentacion de Datos"""

!pip install albumentations==1.4.3 opencv-python-headless==4.10.0.84

import albumentations as A
import numpy as np
import tensorflow as tf

augment = A.Compose([
    A.ElasticTransform(alpha=120, sigma=10, alpha_affine=10, p=0.5),
    A.RandomRotate90(p=0.5),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.3)
])

def augment_data(image, mask):
    def _augment(image_np, mask_np):
        image_np = image_np.numpy()
        mask_np = mask_np.numpy()

        augmented = augment(image=image_np, mask=mask_np)
        return augmented['image'], augmented['mask']

    image, mask = tf.py_function(
        func=_augment,
        inp=[image, mask],
        Tout=[tf.uint8, tf.uint8]
    )

    image.set_shape([None, None, 3])
    mask.set_shape([None, None])
    return image, mask

import matplotlib.pyplot as plt

def visualize_dataset(dataset, num_samples=3):
    """
    Muestra pares (imagen, máscara) del dataset de TensorFlow.
    Compatible con datasets batched.
    """
    for images, masks in dataset.take(num_samples):
        # Si las imágenes vienen en batch, itera dentro del batch
        for i in range(images.shape[0]):
            plt.figure(figsize=(10, 5))

            # Imagen original
            plt.subplot(1, 2, 1)
            plt.imshow(images[i].numpy())
            plt.title("Imagen")
            plt.axis("off")

            # Máscara correspondiente
            plt.subplot(1, 2, 2)
            plt.imshow(masks[i].numpy().squeeze(), cmap="gray")
            plt.title("Máscara")
            plt.axis("off")

            plt.show()

train_dataset = create_tf_dataset(train_coco, train_dir, train_coco.getImgIds())
val_dataset = create_tf_dataset(val_coco, val_dir, val_coco.getImgIds())
test_dataset = create_tf_dataset(test_coco, test_dir, test_coco.getImgIds())

# Aumentacion + preprocesamiento
train_dataset = (
    train_dataset
    .map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)
    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    .shuffle(100)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE)
)

# Validacion y test sin augmentacion
val_dataset = (
    val_dataset
    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
    .prefetch(tf.data.AUTOTUNE)
)

test_dataset = (
    test_dataset
    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    .batch(8)
)

visualize_dataset(train_dataset.take(3))

"""# Modelo"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, concatenate
from tensorflow.keras.layers import ReLU, BatchNormalization, Activation, Input, Add, Multiply
from tensorflow.keras.models import Model
from tensorflow.keras.layers import DepthwiseConv2D

# Bloque de Convolución Profundamente Separable

def ds_block(x, filters, kernel_size=(3, 3), padding="same"):
    # 1. Convolución Profunda (Depthwise)
    # Usa DepthwiseConv2D.
    x = DepthwiseConv2D(kernel_size, padding=padding)(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # 2. Convolución Puntual
    # Usa Conv2D con un kernel de 1x1. Es la que define el número final de 'filters'.
    x = Conv2D(filters, (1, 1), padding=padding)(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    return x

# Bloque de Atención

def attention_gate(g, x, filters):
    # g: señal del Decodificador
    # x: señal del Codificador (skip connection)

    # 1. Proyectar g y x al mismo espacio de baja dimensión
    g_conv = Conv2D(filters, (1, 1), padding='same')(g)
    x_conv = Conv2D(filters, (1, 1), padding='same')(x)

    # 2. Sumar y aplicar ReLU
    sum_relu = ReLU()(Add()([g_conv, x_conv]))

    # 3. Mapear la atencion
    psi = Conv2D(1, (1, 1), padding='same')(sum_relu)
    attention_map = Activation('sigmoid')(psi)

    # 4. Multiplicar el mapa de atención por la señal de entrada (x)
    return Multiply()([x, attention_map])

# Ensamblaje de la Attn-DS-UNet

def attn_ds_unet(input_shape, num_classes=1, start_filters=32):

    inputs = Input(input_shape)

    #  CODIFICADOR (contraccion)
    # Nivel 0
    c0 = Conv2D(start_filters, (3, 3), padding='same', activation='relu')(inputs)
    c0 = ds_block(c0, start_filters)

    # Nivel 1
    c1 = MaxPool2D((2, 2))(c0)
    c1 = ds_block(c1, start_filters * 2)

    # Nivel 2
    c2 = MaxPool2D((2, 2))(c1)
    c2 = ds_block(c2, start_filters * 4)

    # Nivel 3
    c3 = MaxPool2D((2, 2))(c2)
    c3 = ds_block(c3, start_filters * 8)

    #  BOTTLENECK
    b = MaxPool2D((2, 2))(c3)
    b = ds_block(b, start_filters * 16)

    #  DECODIFICADOR (Expansión)
    # Nivel 3 (Expansión)
    u3 = Conv2DTranspose(start_filters * 8, (2, 2), strides=(2, 2), padding='same')(b)
    a3 = attention_gate(u3, c3, start_filters * 8) # Aplicar Atención
    u3 = concatenate([u3, a3])
    u3 = ds_block(u3, start_filters * 8)

    # Nivel 2 (Expansión)
    u2 = Conv2DTranspose(start_filters * 4, (2, 2), strides=(2, 2), padding='same')(u3)
    a2 = attention_gate(u2, c2, start_filters * 4) # Aplicar Atención
    u2 = concatenate([u2, a2])
    u2 = ds_block(u2, start_filters * 4)

    # Nivel 1 (Expansión)
    u1 = Conv2DTranspose(start_filters * 2, (2, 2), strides=(2, 2), padding='same')(u2)
    a1 = attention_gate(u1, c1, start_filters * 2) # Aplicar Atención
    u1 = concatenate([u1, a1])
    u1 = ds_block(u1, start_filters * 2)

    # Nivel 0 (Expansión)
    u0 = Conv2DTranspose(start_filters, (2, 2), strides=(2, 2), padding='same')(u1)
    a0 = attention_gate(u0, c0, start_filters) # Aplicar Atención
    u0 = concatenate([u0, a0])
    u0 = ds_block(u0, start_filters)

    #  CAPA DE SALIDA
    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid', dtype='float32')(u0)

    return Model(inputs=inputs, outputs=outputs)

input_size = (512, 512, 3)
model = attn_ds_unet(input_size)

model.summary()

"""# Entrenamiento"""

from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')
print("Política actual:", mixed_precision.global_policy())

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# Compilación del modelo
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss=combined_loss,
    metrics=[dice_coef]
)

# Callbacks
checkpoint = ModelCheckpoint(
    'best_model.h5',
    monitor='val_dice_coef',
    mode='max',
    save_best_only=True,
    verbose=1
)

early_stop = EarlyStopping(
    monitor='val_dice_coef',
    patience=10,
    mode='max',
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_dice_coef',
    factor=0.5,
    patience=5,
    mode='max',
    min_lr=1e-6,
    verbose=1
)

# Entrenamiento
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=40,
    callbacks=[checkpoint, early_stop, reduce_lr]
)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['dice_coef'], label='Train Dice')
plt.plot(history.history['val_dice_coef'], label='Val Dice')
plt.xlabel('Epoch')
plt.ylabel('Dice Coefficient')
plt.legend()
plt.title('Dice Coefficient')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss')

plt.show()

test_results = model.evaluate(test_dataset)
print(f"\nTest Dice Coefficient: {test_results[1]:.4f}")
print(f"Test Accuracy: {test_results[2]:.4f}")

import numpy as np
import matplotlib.pyplot as plt

def visualize_predictions(dataset, model, num_samples=3):
    for images, masks in dataset.take(1):
        preds = model.predict(images)
        preds = (preds > 0.5).astype(np.uint8)

        for i in range(num_samples):
            plt.figure(figsize=(12, 4))

            plt.subplot(1, 3, 1)
            plt.imshow(images[i])
            plt.title("Imagen")
            plt.axis("off")

            plt.subplot(1, 3, 2)
            plt.imshow(masks[i], cmap="gray")
            plt.title("Máscara real")
            plt.axis("off")

            plt.subplot(1, 3, 3)
            plt.imshow(preds[i], cmap="gray")
            plt.title("Predicción")
            plt.axis("off")

            plt.show()

visualize_predictions(test_dataset, model)